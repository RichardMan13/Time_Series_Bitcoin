{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_metrics(y_truth, y_forecasted): \n",
    "\n",
    "    mae = round(mean_absolute_error(y_truth, y_forecasted) ,8)\n",
    "    mape = round(np.mean(np.abs((y_truth - y_forecasted) / y_truth)) * 100, 8)\n",
    "    mse = round(mean_squared_error(y_truth, y_forecasted), 8)\n",
    "    rmse = round(mse**(0.5), 8)\n",
    "    rmspe = round((np.sqrt(np.mean(np.square((y_truth - y_forecasted) / y_truth)))) * 100, 8)\n",
    "    r2 = round(r2_score(y_truth, y_forecasted), 8)\n",
    "    try:\n",
    "        corr, _ = pearsonr(y_truth, y_forecasted)\n",
    "        pearson = round(corr, 8)\n",
    "    except:\n",
    "        pearson = None\n",
    "\n",
    "    return mae, mape, mse, rmse, rmspe, r2, pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file test_lstm_1d_50_epochs.csv\n",
      "mape 4.66162511 rmse 546.07673667 r2 0.86995575\n",
      "file test_lstm_1d_100_epochs.csv\n",
      "mape 5.37213209 rmse 617.41926897 r2 0.8337567\n",
      "file test_lstm_1d_150_epochs.csv\n",
      "mape 3.64972665 rmse 445.40763257 r2 0.91348347\n",
      "file test_lstm_1d_200_epochs.csv\n",
      "mape 4.88278821 rmse 542.01540398 r2 0.87188291\n",
      "file test_lstm_1d_250_epochs.csv\n",
      "mape 3.82913931 rmse 471.18479216 r2 0.90317972\n",
      "file test_lstm_1d_300_epochs.csv\n",
      "mape 5.22126251 rmse 569.94876499 r2 0.85833733\n",
      "file test_lstm_1d_350_epochs.csv\n",
      "mape 3.29453651 rmse 417.46285666 r2 0.92399897\n",
      "file test_lstm_1d_400_epochs.csv\n",
      "mape 3.10772247 rmse 407.6693117 r2 0.92752306\n"
     ]
    }
   ],
   "source": [
    "# file = 'test_lstm_1d_50_epochs.csv'\n",
    "# file = 'test_lstm_1d_200_epochs.csv'\n",
    "# file = 'test_lstm_1d_400_epochs.csv'\n",
    "list_files = ['test_lstm_1d_50_epochs.csv','test_lstm_1d_100_epochs.csv', 'test_lstm_1d_150_epochs.csv', 'test_lstm_1d_200_epochs.csv', \n",
    "              'test_lstm_1d_250_epochs.csv', 'test_lstm_1d_300_epochs.csv', 'test_lstm_1d_350_epochs.csv', 'test_lstm_1d_400_epochs.csv']\n",
    "\n",
    "for file in list_files:\n",
    "\n",
    "    df_aux = pd.read_csv('/home/ricardo/Documentos/TCC_FILES/TCC/'+file, sep = '\\t')\n",
    "\n",
    "    mae, mape, mse, rmse, rmspe, r2, pearson = perform_metrics(df_aux['y_test'], df_aux['y_test_predict'])\n",
    "    print('file', file)\n",
    "    print('mape', mape, 'rmse', rmse, 'r2', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lstm_1d_50_epochs\n",
    "mape 4.66162511 rmse 546.07673667 r2 0.86995575\n",
    "\n",
    "test_lstm_1d_200_epochs\n",
    "mape 4.88278821 rmse 542.01540398 r2 0.87188291\n",
    "\n",
    "test_lstm_1d_400_epochs\n",
    "mape 3.10772247 rmse 407.6693117 r2 0.92752306"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_arima_1d.csv',\n",
       " 'train_prophet_1d.csv',\n",
       " 'train_ma_1h.csv',\n",
       " 'test_lstm_1d.csv',\n",
       " 'train_naive_1h.csv',\n",
       " 'train_ses_1d.csv',\n",
       " 'train_prophet_1h.csv',\n",
       " 'train_ma_1d.csv',\n",
       " 'train_lstm_1d.csv',\n",
       " 'test_ses_1h.csv',\n",
       " 'test_lstm_1h.csv',\n",
       " 'train_arima_1h.csv',\n",
       " 'test_naive_1d.csv',\n",
       " 'train_ar_1d.csv',\n",
       " 'train_lstm_1h.csv',\n",
       " 'test_naive_1h.csv',\n",
       " 'test_arima_1d.csv',\n",
       " 'test_prophet_1h.csv',\n",
       " 'test_ma_1h.csv',\n",
       " 'test_ar_1h.csv',\n",
       " 'test_ma_1d.csv',\n",
       " 'test_ar_1d.csv',\n",
       " 'train_ses_1h.csv',\n",
       " 'test_prophet_1d.csv',\n",
       " 'train_ar_1h.csv',\n",
       " 'test_ses_1d.csv',\n",
       " 'test_arima_1h.csv',\n",
       " 'train_naive_1d.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_files = os.listdir('datasets/train_test_remake')\n",
    "list_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params = {\n",
    "#     'test_ma_1d.csv': {'p_order': 0, 'd_order': 1, 'q_order': 5},\n",
    "#     'test_ma_1h.csv': {'p_order': 0, 'd_order': 1, 'q_order': 2},\n",
    "#     'test_naive_1h.csv': {None},\n",
    "#     'test_naive_1d.csv': {None},\n",
    "#     'test_prophet_1h.csv': {'diff_order': 1},\n",
    "#     'test_prophet_1d.csv': {'diff_order': 1},\n",
    "#     'test_ses_1d.csv': {'alpha': 0.9},\n",
    "#     'test_ses_1h.csv': {'alpha': 0.9},\n",
    "#     'test_ar_1d.csv': {'p_order': 5, 'd_order': 1, 'q_order': 0},\n",
    "#     'test_ar_1h.csv': {'p_order': 4, 'd_order': 1, 'q_order': 0},\n",
    "#     'test_arima_1d.csv': {'p_order': 5, 'd_order': 0, 'q_order': 4},\n",
    "#     'test_arima_1h.csv': {'p_order': 4, 'd_order': 1, 'q_order': 3},\n",
    "#     'test_lstm_1d.csv': {'batch_size': 5, 'num_units': 50, 'epochs': 200},\n",
    "#     'test_lstm_1h.csv': {'batch_size': 100, 'num_units': 100, 'epochs': 200},\n",
    "# }\n",
    "\n",
    "best_params = {\n",
    "    'test_ma_1d.csv': {\"ordem_p\": 0, \"ordem_d\": 1, \"ordem_q\": 5},\n",
    "    'test_ma_1h.csv': {\"ordem_p\": 0, \"ordem_d\": 1, \"ordem_q\": 2},\n",
    "    'test_naive_1h.csv': {},\n",
    "    'test_naive_1d.csv': {},\n",
    "    'test_prophet_1h.csv': {\"ordem_d\": 1},\n",
    "    'test_prophet_1d.csv': {\"ordem_d\": 1},\n",
    "    'test_ses_1d.csv': {\"alfa\": 0.9},\n",
    "    'test_ses_1h.csv': {\"alfa\": 0.9},\n",
    "    'test_ar_1d.csv': {\"ordem_p\": 5, \"ordem_d\": 1, \"ordem_q\": 0},\n",
    "    'test_ar_1h.csv': {\"ordem_p\": 4, \"ordem_d\": 1, \"ordem_q\": 0},\n",
    "    'test_arima_1d.csv': {\"ordem_p\": 4, \"ordem_d\": 1, \"ordem_q\": 5},\n",
    "    'test_arima_1h.csv': {\"ordem_p\": 4, \"ordem_d\": 1, \"ordem_q\": 3},\n",
    "    'test_lstm_1d.csv': {\"lote\": 5, \"unidades\": 100, \"ciclos\": 400},\n",
    "    'test_lstm_1h.csv': {\"lote\": 100, \"unidades\": 100, \"ciclos\": 200},\n",
    "}\n",
    "\n",
    "data = {\n",
    "    'model': [],\n",
    "    'periodicity': [],\n",
    "    'best_params': [],\n",
    "    'mae': [],\n",
    "    'mape': [],\n",
    "    'mse': [],\n",
    "    'rmse': [],\n",
    "    'rmspe': [],\n",
    "    'r2': [],\n",
    "    'pearson': []\n",
    "}\n",
    "\n",
    "list_files = os.listdir('datasets/train_test_remake')\n",
    "\n",
    "for file in list_files:\n",
    "    \n",
    "    file_aux = file.split('_')\n",
    "    \n",
    "    if file_aux[0] == 'test':\n",
    "        \n",
    "        df_aux = pd.read_csv('datasets/train_test_remake/'+file, sep = '\\t')\n",
    "        \n",
    "        mae, mape, mse, rmse, rmspe, r2, pearson = perform_metrics(df_aux['y_test'], df_aux['y_test_predict'])\n",
    "        \n",
    "        model = file_aux[1].upper()\n",
    "        periodicity = file_aux[2].split('.')[0].upper()\n",
    "\n",
    "        data['model'].append(model)\n",
    "        data['periodicity'].append(periodicity)\n",
    "        data['best_params'].append(best_params[file])\n",
    "        data['mae'].append(mae)\n",
    "        data['mape'].append(mape)\n",
    "        data['mse'].append(mse)\n",
    "        data['rmse'].append(rmse)\n",
    "        data['rmspe'].append(rmspe)\n",
    "        data['r2'].append(r2)\n",
    "        data['pearson'].append(pearson)\n",
    "        \n",
    "df_metrics = pd.DataFrame(data).sort_values(by=['model']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SES</td>\n",
       "      <td>0.5044</td>\n",
       "      <td>82.8227</td>\n",
       "      <td>0.9970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MA</td>\n",
       "      <td>0.5046</td>\n",
       "      <td>82.8333</td>\n",
       "      <td>0.9970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARIMA</td>\n",
       "      <td>0.5051</td>\n",
       "      <td>82.8410</td>\n",
       "      <td>0.9970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR</td>\n",
       "      <td>0.5047</td>\n",
       "      <td>82.8553</td>\n",
       "      <td>0.9970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NAIVE</td>\n",
       "      <td>0.5058</td>\n",
       "      <td>83.0016</td>\n",
       "      <td>0.9970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PROPHET</td>\n",
       "      <td>0.5062</td>\n",
       "      <td>83.0408</td>\n",
       "      <td>0.9970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>89.3332</td>\n",
       "      <td>0.9965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Modelo    MAPE     RMSE      R²\n",
       "0      SES  0.5044  82.8227  0.9970\n",
       "1       MA  0.5046  82.8333  0.9970\n",
       "2    ARIMA  0.5051  82.8410  0.9970\n",
       "3       AR  0.5047  82.8553  0.9970\n",
       "4    NAIVE  0.5058  83.0016  0.9970\n",
       "5  PROPHET  0.5062  83.0408  0.9970\n",
       "6     LSTM  0.6333  89.3332  0.9965"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics = df_metrics.sort_values(by=['rmse']).reset_index(drop = True)\n",
    "a = df_metrics[df_metrics['periodicity'] == '1H'].copy()\n",
    "a.columns = ['Modelo', 'Periodicidade', 'Melhores parametros', 'MAE', 'MAPE', 'MSE', 'RMSE', 'RMSPE', 'R²', 'Pearson']\n",
    "a = a.drop(columns = ['MAE', 'MSE', 'RMSPE', 'Pearson'])\n",
    "a = a.drop(columns = ['Melhores parametros', 'Periodicidade'])\n",
    "# a = a.drop(columns = ['MAPE', 'RMSE', 'R²', 'Periodicidade'])\n",
    "a.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
